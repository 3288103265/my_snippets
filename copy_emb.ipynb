{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Copy embedding weights."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb1 = torch.nn.Embedding(3,4)\n",
    "emb2 = torch.nn.Embedding(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__constants__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_pre_hooks',\n",
       " '_get_name',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'embedding_dim',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'from_pretrained',\n",
       " 'half',\n",
       " 'load_state_dict',\n",
       " 'max_norm',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'norm_type',\n",
       " 'num_embeddings',\n",
       " 'padding_idx',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_parameter',\n",
       " 'requires_grad_',\n",
       " 'reset_parameters',\n",
       " 'scale_grad_by_freq',\n",
       " 'share_memory',\n",
       " 'sparse',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'weight',\n",
       " 'zero_grad']"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "dir(emb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.5733,  0.4727,  2.3292,  0.3882],\n",
       "        [-0.8442,  0.3685, -0.2390, -0.8850],\n",
       "        [ 0.9971, -0.3312,  0.9892,  0.7570]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "emb1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.5407, -0.5171,  0.1301, -0.0244],\n",
       "        [-1.3310, -0.6862,  0.4079, -1.3477],\n",
       "        [ 0.4531, -1.1278, -1.2002,  0.2824]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "emb2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb3 = copy.deepcopy(emb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.5733,  0.4727,  2.3292,  0.3882],\n",
       "        [-0.8442,  0.3685, -0.2390, -0.8850],\n",
       "        [ 0.9971, -0.3312,  0.9892,  0.7570]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "emb3.weight"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Embedding(3, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "emb2.from_pretrained(emb1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.5407, -0.5171,  0.1301, -0.0244],\n",
       "        [-1.3310, -0.6862,  0.4079, -1.3477],\n",
       "        [ 0.4531, -1.1278, -1.2002,  0.2824]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "emb2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb2 = emb2.from_pretrained(emb1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.5733,  0.4727,  2.3292,  0.3882],\n",
       "        [-0.8442,  0.3685, -0.2390, -0.8850],\n",
       "        [ 0.9971, -0.3312,  0.9892,  0.7570]])"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "emb2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([-0.5733,  0.4727,  2.3292,  0.3882], grad_fn=<EmbeddingBackward>)\ntensor([-0.5733,  0.4727,  2.3292,  0.3882])\n"
     ]
    }
   ],
   "source": [
    "# no grad.\n",
    "print(emb1(torch.tensor(0)))\n",
    "print(emb2(torch.tensor(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Embedding(3, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "emb2.apply(emb1.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb2 = emb2.apply(emb1.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\ntensor([[-0.7352,  1.3280, -0.3746,  1.4420],\n        [-2.6702, -0.6714,  0.2365,  0.6400],\n        [ 1.8743, -0.5686, -1.7243,  0.5487]], requires_grad=True)\nParameter containing:\ntensor([[-0.7352,  1.3280, -0.3746,  1.4420],\n        [-2.6702, -0.6714,  0.2365,  0.6400],\n        [ 1.8743, -0.5686, -1.7243,  0.5487]], requires_grad=True)\nParameter containing:\ntensor([[-0.5733,  0.4727,  2.3292,  0.3882],\n        [-0.8442,  0.3685, -0.2390, -0.8850],\n        [ 0.9971, -0.3312,  0.9892,  0.7570]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "emb3 = torch.nn.Embedding(3,4)\n",
    "print(emb3.weight)\n",
    "emb3 = emb3.apply(emb1.parameters)\n",
    "print(emb3.weight)\n",
    "print(emb1.weight) # apply dont change weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}